{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a879d4c",
   "metadata": {},
   "source": [
    "# Llama2-Powered AI Solution for Clinical Study Reports (CSR)\n",
    "This notebook automates **extraction, summarization, and generation** of Clinical Study Reports using **Llama2**.\n",
    "It also integrates **Langfuse** for observability, real-time monitoring, and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Required Packages\n",
    "!pip install torch transformers fastapi uvicorn PyPDF2 langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d17056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2  # PDF extraction\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "import langfuse\n",
    "import uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eba037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Langfuse API\n",
    "LANGFUSE_SECRET_KEY = \"your_langfuse_secret_key\"\n",
    "langfuse.init(secret_key=LANGFUSE_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f7aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Llama2 Model\n",
    "MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51493715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        for page in pdf_reader.pages:\n",
    "            extracted_text = page.extract_text()\n",
    "            if extracted_text:\n",
    "                text += extracted_text + \"\\n\"\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization using Llama2\n",
    "def summarize_text(text, max_length=512):\n",
    "    prompt = f\"Summarize the following Clinical Study Report: {text[:4000]}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "    summary_ids = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Clinical Study Report\n",
    "def generate_text(text, max_length=1024):\n",
    "    prompt = f\"Generate a comprehensive Clinical Study Report based on: {text[:4000]}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
    "    output_ids = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langfuse Logging\n",
    "langfuse.log(\"llama2_summary\", input_text=\"sample input\", output_text=\"sample summary\")\n",
    "langfuse.log(\"llama2_generated_report\", input_text=\"sample input\", output_text=\"sample report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e674a26",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Fine-tune Llama2 for medical NLP\n",
    "- Optimize prompt engineering\n",
    "- Deploy the API using AWS/GCP\n",
    "- Implement document indexing for structured CSR handling"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
